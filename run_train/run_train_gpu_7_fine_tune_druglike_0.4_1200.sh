CUDA_VISIBLE_DEVICES="7" metaseq-train --task streaming_language_modeling ../Molecular_Generation_with_GDB13/data/data_bin_druglike_0.4_sf_4K/ --finetune-from-model ./checkpoints/OPT_1.2B_ep_1_all_sf_848M_2.00E-04/checkpoint_last.pt --sample-break-mode "eos_pad_8" --hf-tokenizer ../Molecular_Generation_with_GDB13/data/tokenizers/tokenizer_sf/tokenizer.json --train-subset train --valid-subset valid --combine-valid-subsets --no-reshard-after-forward --use-sharded-state --checkpoint-activations --full-megatron-init --megatron-init-sigma 0.006 --activation-fn relu --arch transformer_lm --share-decoder-input-output-embed --decoder-layers 24 --decoder-embed-dim 2048 --decoder-ffn-embed-dim 8192 --decoder-attention-heads 32 --decoder-learned-pos --no-scale-embedding --dropout 0.0 --attention-dropout 0.0 --no-emb-dropout --weight-decay 0.1 --optimizer adam --adam-betas  "(0.9, 0.95)" --adam-eps 1e-08 --clip-norm 1.0 --clip-norm-type l2 --criterion cross_entropy --required-batch-size-multiple 1 --distributed-world-size 1 --model-parallel-size 1 --ddp-backend pytorch_ddp --memory-efficient-fp16 --fp16-init-scale 4 --fp16 --seed 1 --num-workers 0 --num-workers-valid 0 --lr-scheduler polynomial_decay --lr 2.00E-05 --end-learning-rate 2.00E-06 --warmup-updates 3 --total-num-update 31 --max-update 31 --tokens-per-sample 64 --batch-size 128 --update-freq 1 --log-format json --log-interval 1 --ignore-unused-valid-subsets --validate-interval-updates 500 --wandb-project Scaling_Laws --wandb-run-name OPT_1.2B_ep_1_druglike_0.4_sf_4K_2.00E-05 --save-interval-epochs 100 --keep-last-updates 1 --save-dir ./checkpoints/OPT_1.2B_ep_1_druglike_0.4_sf_4K_2.00E-05







CUDA_VISIBLE_DEVICES="7" metaseq-train --task streaming_language_modeling ../Molecular_Generation_with_GDB13/data/data_bin_druglike_0.4_sf_16K/ --finetune-from-model ./checkpoints/OPT_1.2B_ep_1_all_sf_848M_2.00E-04/checkpoint_last.pt --sample-break-mode "eos_pad_8" --hf-tokenizer ../Molecular_Generation_with_GDB13/data/tokenizers/tokenizer_sf/tokenizer.json --train-subset train --valid-subset valid --combine-valid-subsets --no-reshard-after-forward --use-sharded-state --checkpoint-activations --full-megatron-init --megatron-init-sigma 0.006 --activation-fn relu --arch transformer_lm --share-decoder-input-output-embed --decoder-layers 24 --decoder-embed-dim 2048 --decoder-ffn-embed-dim 8192 --decoder-attention-heads 32 --decoder-learned-pos --no-scale-embedding --dropout 0.0 --attention-dropout 0.0 --no-emb-dropout --weight-decay 0.1 --optimizer adam --adam-betas  "(0.9, 0.95)" --adam-eps 1e-08 --clip-norm 1.0 --clip-norm-type l2 --criterion cross_entropy --required-batch-size-multiple 1 --distributed-world-size 1 --model-parallel-size 1 --ddp-backend pytorch_ddp --memory-efficient-fp16 --fp16-init-scale 4 --fp16 --seed 1 --num-workers 0 --num-workers-valid 0 --lr-scheduler polynomial_decay --lr 2.00E-05 --end-learning-rate 2.00E-06 --warmup-updates 13 --total-num-update 125 --max-update 125 --tokens-per-sample 64 --batch-size 128 --update-freq 1 --log-format json --log-interval 1 --ignore-unused-valid-subsets --validate-interval-updates 500 --wandb-project Scaling_Laws --wandb-run-name OPT_1.2B_ep_1_druglike_0.4_sf_16K_2.00E-05 --save-interval-epochs 100 --keep-last-updates 1 --save-dir ./checkpoints/OPT_1.2B_ep_1_druglike_0.4_sf_16K_2.00E-05







CUDA_VISIBLE_DEVICES="7" metaseq-train --task streaming_language_modeling ../Molecular_Generation_with_GDB13/data/data_bin_druglike_0.4_sf_64K/ --finetune-from-model ./checkpoints/OPT_1.2B_ep_1_all_sf_848M_2.00E-04/checkpoint_last.pt --sample-break-mode "eos_pad_8" --hf-tokenizer ../Molecular_Generation_with_GDB13/data/tokenizers/tokenizer_sf/tokenizer.json --train-subset train --valid-subset valid --combine-valid-subsets --no-reshard-after-forward --use-sharded-state --checkpoint-activations --full-megatron-init --megatron-init-sigma 0.006 --activation-fn relu --arch transformer_lm --share-decoder-input-output-embed --decoder-layers 24 --decoder-embed-dim 2048 --decoder-ffn-embed-dim 8192 --decoder-attention-heads 32 --decoder-learned-pos --no-scale-embedding --dropout 0.0 --attention-dropout 0.0 --no-emb-dropout --weight-decay 0.1 --optimizer adam --adam-betas  "(0.9, 0.95)" --adam-eps 1e-08 --clip-norm 1.0 --clip-norm-type l2 --criterion cross_entropy --required-batch-size-multiple 1 --distributed-world-size 1 --model-parallel-size 1 --ddp-backend pytorch_ddp --memory-efficient-fp16 --fp16-init-scale 4 --fp16 --seed 1 --num-workers 0 --num-workers-valid 0 --lr-scheduler polynomial_decay --lr 2.00E-05 --end-learning-rate 2.00E-06 --warmup-updates 50 --total-num-update 500 --max-update 500 --tokens-per-sample 64 --batch-size 128 --update-freq 1 --log-format json --log-interval 1 --ignore-unused-valid-subsets --validate-interval-updates 500 --wandb-project Scaling_Laws --wandb-run-name OPT_1.2B_ep_1_druglike_0.4_sf_64K_2.00E-05 --save-interval-epochs 100 --keep-last-updates 1 --save-dir ./checkpoints/OPT_1.2B_ep_1_druglike_0.4_sf_64K_2.00E-05







CUDA_VISIBLE_DEVICES="7" metaseq-train --task streaming_language_modeling ../Molecular_Generation_with_GDB13/data/data_bin_druglike_0.4_sf_256K/ --finetune-from-model ./checkpoints/OPT_1.2B_ep_1_all_sf_848M_2.00E-04/checkpoint_last.pt --sample-break-mode "eos_pad_8" --hf-tokenizer ../Molecular_Generation_with_GDB13/data/tokenizers/tokenizer_sf/tokenizer.json --train-subset train --valid-subset valid --combine-valid-subsets --no-reshard-after-forward --use-sharded-state --checkpoint-activations --full-megatron-init --megatron-init-sigma 0.006 --activation-fn relu --arch transformer_lm --share-decoder-input-output-embed --decoder-layers 24 --decoder-embed-dim 2048 --decoder-ffn-embed-dim 8192 --decoder-attention-heads 32 --decoder-learned-pos --no-scale-embedding --dropout 0.0 --attention-dropout 0.0 --no-emb-dropout --weight-decay 0.1 --optimizer adam --adam-betas  "(0.9, 0.95)" --adam-eps 1e-08 --clip-norm 1.0 --clip-norm-type l2 --criterion cross_entropy --required-batch-size-multiple 1 --distributed-world-size 1 --model-parallel-size 1 --ddp-backend pytorch_ddp --memory-efficient-fp16 --fp16-init-scale 4 --fp16 --seed 1 --num-workers 0 --num-workers-valid 0 --lr-scheduler polynomial_decay --lr 2.00E-05 --end-learning-rate 2.00E-06 --warmup-updates 200 --total-num-update 2000 --max-update 2000 --tokens-per-sample 64 --batch-size 128 --update-freq 1 --log-format json --log-interval 1 --ignore-unused-valid-subsets --validate-interval-updates 500 --wandb-project Scaling_Laws --wandb-run-name OPT_1.2B_ep_1_druglike_0.4_sf_256K_2.00E-05 --save-interval-epochs 100 --keep-last-updates 1 --save-dir ./checkpoints/OPT_1.2B_ep_1_druglike_0.4_sf_256K_2.00E-05







CUDA_VISIBLE_DEVICES="7" metaseq-train --task streaming_language_modeling ../Molecular_Generation_with_GDB13/data/data_bin_druglike_0.4_sf_1000K/ --finetune-from-model ./checkpoints/OPT_1.2B_ep_1_all_sf_848M_2.00E-04/checkpoint_last.pt --sample-break-mode "eos_pad_8" --hf-tokenizer ../Molecular_Generation_with_GDB13/data/tokenizers/tokenizer_sf/tokenizer.json --train-subset train --valid-subset valid --combine-valid-subsets --no-reshard-after-forward --use-sharded-state --checkpoint-activations --full-megatron-init --megatron-init-sigma 0.006 --activation-fn relu --arch transformer_lm --share-decoder-input-output-embed --decoder-layers 24 --decoder-embed-dim 2048 --decoder-ffn-embed-dim 8192 --decoder-attention-heads 32 --decoder-learned-pos --no-scale-embedding --dropout 0.0 --attention-dropout 0.0 --no-emb-dropout --weight-decay 0.1 --optimizer adam --adam-betas  "(0.9, 0.95)" --adam-eps 1e-08 --clip-norm 1.0 --clip-norm-type l2 --criterion cross_entropy --required-batch-size-multiple 1 --distributed-world-size 1 --model-parallel-size 1 --ddp-backend pytorch_ddp --memory-efficient-fp16 --fp16-init-scale 4 --fp16 --seed 1 --num-workers 0 --num-workers-valid 0 --lr-scheduler polynomial_decay --lr 2.00E-05 --end-learning-rate 2.00E-06 --warmup-updates 781 --total-num-update 7813 --max-update 7813 --tokens-per-sample 64 --batch-size 128 --update-freq 1 --log-format json --log-interval 1 --ignore-unused-valid-subsets --validate-interval-updates 500 --wandb-project Scaling_Laws --wandb-run-name OPT_1.2B_ep_1_druglike_0.4_sf_1000K_2.00E-05 --save-interval-epochs 100 --keep-last-updates 1 --save-dir ./checkpoints/OPT_1.2B_ep_1_druglike_0.4_sf_1000K_2.00E-05


