{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2279d90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selfies as sf\n",
    "from rdkit import Chem\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19324ac0",
   "metadata": {},
   "source": [
    "### Run example from the Original SELFIES paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "680f78b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[C]', '[=C]', '[C]', '[=C]', '[C]', '[=C]', '[Ring1]', '[=Branch1]']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From https://github.com/aspuru-guzik-group/selfies\n",
    "\n",
    "benzene = \"c1ccccc1\"\n",
    "\n",
    "# SMILES -> SELFIES -> SMILES translation\n",
    "try:\n",
    "    benzene_sf = sf.encoder(benzene)  # [C][=C][C][=C][C][=C][Ring1][=Branch1]\n",
    "    benzene_smi = sf.decoder(benzene_sf)  # C1=CC=CC=C1\n",
    "except sf.EncoderError:\n",
    "    pass  # sf.encoder error!\n",
    "except sf.DecoderError:\n",
    "    pass  # sf.decoder error!\n",
    "\n",
    "len_benzene = sf.len_selfies(benzene_sf)  # 8\n",
    "\n",
    "symbols_benzene = list(sf.split_selfies(benzene_sf))\n",
    "symbols_benzene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d3667f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c1ccccc1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if benzene is canonical\n",
    "canonical_benzene = Chem.MolToSmiles(Chem.MolFromSmiles(benzene))\n",
    "canonical_benzene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2783ed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C1=CC=CC=C1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output of selfies -> smiles\n",
    "benzene_smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "647ec140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c1ccccc1'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make canonical\n",
    "Chem.MolToSmiles(Chem.MolFromSmiles(benzene_smi))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d442779",
   "metadata": {},
   "source": [
    "### Make tokenizer json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f3cdd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_molgen = AutoTokenizer.from_pretrained(\"zjunlp/MolGen-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "930478a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BartTokenizerFast(name_or_path='zjunlp/MolGen-large', vocab_size=4, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'eos_token': AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'unk_token': AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'sep_token': AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'pad_token': AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'cls_token': AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'mask_token': AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=True)}, clean_up_tokenization_spaces=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_molgen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11a37f67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'[11CH3]': 107,\n",
       " '[B@H1-1]': 121,\n",
       " '[18F]': 97,\n",
       " '[#S]': 40,\n",
       " '[=C]': 35,\n",
       " '[P@H1]': 81,\n",
       " '[/C@]': 31,\n",
       " '[N-1]': 84,\n",
       " '[\\\\Cl]': 37,\n",
       " '[C@@H1]': 15,\n",
       " '[S@+1]': 72,\n",
       " '[/O]': 69,\n",
       " '[Ring2]': 90,\n",
       " '[/B]': 125,\n",
       " '[P@@]': 59,\n",
       " '[PH2]': 51,\n",
       " '[N]': 19,\n",
       " '[N@+1]': 111,\n",
       " '[S]': 60,\n",
       " '[=S@@+1]': 42,\n",
       " '[\\\\CH0]': 176,\n",
       " '[\\\\CH1-1]': 153,\n",
       " '[\\\\Br]': 142,\n",
       " '[S@@H1]': 45,\n",
       " '[Br]': 62,\n",
       " '[Br+1]': 166,\n",
       " '[\\\\B]': 159,\n",
       " '[=PH1]': 132,\n",
       " '[\\\\NH1]': 103,\n",
       " '[S+1]': 61,\n",
       " '[/F]': 6,\n",
       " '[S@@]': 154,\n",
       " '[/I]': 83,\n",
       " '[#N]': 23,\n",
       " '[/N]': 67,\n",
       " '<s>': 0,\n",
       " '[\\\\S@@]': 180,\n",
       " '[#Branch2]': 178,\n",
       " '[=Branch1]': 33,\n",
       " '[/123I]': 7,\n",
       " '[=N+1]': 144,\n",
       " '[B@-1]': 179,\n",
       " '[127I]': 36,\n",
       " '[\\\\P]': 74,\n",
       " '[\\\\C@]': 145,\n",
       " '[=S@]': 44,\n",
       " '[\\\\C@H1]': 49,\n",
       " '[124I]': 136,\n",
       " '[Si]': 119,\n",
       " '[/C@@H1]': 13,\n",
       " '[-/Ring2]': 156,\n",
       " '[=P@@]': 53,\n",
       " '[=O+1]': 96,\n",
       " '[SH0]': 182,\n",
       " '[/CH1-1]': 88,\n",
       " '[\\\\Si]': 168,\n",
       " '[S@@+1]': 57,\n",
       " '[P@+1]': 158,\n",
       " '[#P]': 87,\n",
       " '[CH2-1]': 110,\n",
       " '[Sn]': 114,\n",
       " '[\\\\SH1]': 151,\n",
       " '<mask>': 184,\n",
       " '[=SH1]': 117,\n",
       " '[/NH1]': 24,\n",
       " '[F]': 66,\n",
       " '[/C]': 118,\n",
       " '[/Cl]': 155,\n",
       " '[N@@+1]': 131,\n",
       " '[P@@H1]': 170,\n",
       " '[C@H1]': 29,\n",
       " '[BH2-1]': 91,\n",
       " '[I]': 63,\n",
       " '[SnH1]': 109,\n",
       " '[P@]': 175,\n",
       " '[C+1]': 65,\n",
       " '[C@@]': 173,\n",
       " '[P+1]': 82,\n",
       " '[=P@]': 157,\n",
       " '[C]': 139,\n",
       " '[CH2]': 146,\n",
       " '[CH0]': 28,\n",
       " '[\\\\S@]': 116,\n",
       " '[S@]': 93,\n",
       " '[=S@@H1]': 106,\n",
       " '[=Ring2]': 52,\n",
       " '[-\\\\Ring2]': 34,\n",
       " '[O+1]': 85,\n",
       " '[NH1]': 130,\n",
       " '[=S@@]': 5,\n",
       " '[SH1]': 123,\n",
       " '[=CH0]': 78,\n",
       " '[\\\\O]': 18,\n",
       " '[BH1-1]': 54,\n",
       " '[B-1]': 122,\n",
       " '[\\\\C]': 43,\n",
       " '[/S@@]': 160,\n",
       " '[=P@H1]': 147,\n",
       " '[=P@@H1]': 32,\n",
       " '[/S@@+1]': 21,\n",
       " '[3H]': 137,\n",
       " '[Ring1]': 70,\n",
       " '[=O]': 30,\n",
       " '[18OH1]': 76,\n",
       " '[/N+1]': 152,\n",
       " '[/C@H1]': 177,\n",
       " '[#C-1]': 181,\n",
       " '[\\\\C@@]': 46,\n",
       " '[/P]': 79,\n",
       " '[125I]': 39,\n",
       " '[/OH0]': 174,\n",
       " '[=S]': 73,\n",
       " '[\\\\123I]': 89,\n",
       " '[\\\\I]': 172,\n",
       " '<pad>': 1,\n",
       " '[\\\\N]': 138,\n",
       " '[\\\\C@@H1]': 22,\n",
       " '[-\\\\Ring1]': 164,\n",
       " '[Branch1]': 104,\n",
       " '[/O-1]': 171,\n",
       " '[\\\\S]': 48,\n",
       " '[Sn+3]': 135,\n",
       " '[SH2]': 101,\n",
       " '[\\\\S+1]': 95,\n",
       " '<unk>': 3,\n",
       " '[=N]': 105,\n",
       " '[\\\\O-1]': 141,\n",
       " '[P]': 80,\n",
       " '[=S+1]': 133,\n",
       " '[=P]': 86,\n",
       " '</s>': 2,\n",
       " '[SnH2]': 99,\n",
       " '[/C@@]': 14,\n",
       " '[#Branch1]': 12,\n",
       " '[B@@-1]': 17,\n",
       " '[/Si]': 38,\n",
       " '[/Br]': 149,\n",
       " '[\\\\S@@+1]': 169,\n",
       " '[=Ring1]': 163,\n",
       " '[#Ring1]': 128,\n",
       " '[/S@]': 77,\n",
       " '[/CH0]': 126,\n",
       " '[=Branch2]': 100,\n",
       " '[=S@+1]': 167,\n",
       " '[/P@@]': 16,\n",
       " '[#N+1]': 120,\n",
       " '[PH1]': 134,\n",
       " '[123I]': 124,\n",
       " '[SH3]': 102,\n",
       " '[N@@H1+1]': 162,\n",
       " '[N+1]': 150,\n",
       " '[Branch2]': 140,\n",
       " '[B@@H1-1]': 56,\n",
       " '[=NH0]': 27,\n",
       " '[CH1]': 115,\n",
       " '[/CH1]': 10,\n",
       " '[/C-1]': 68,\n",
       " '[BH3-1]': 75,\n",
       " '[\\\\N+1]': 92,\n",
       " '[CH1-1]': 4,\n",
       " '[B]': 108,\n",
       " '[/NH0]': 55,\n",
       " '[=P+1]': 98,\n",
       " '[Cl]': 11,\n",
       " '[\\\\C-1]': 127,\n",
       " '[#C]': 165,\n",
       " '[CH1+1]': 41,\n",
       " '[=B]': 25,\n",
       " '[/S]': 112,\n",
       " '[C-1]': 8,\n",
       " '[F+1]': 50,\n",
       " '[\\\\F]': 26,\n",
       " '[C@]': 9,\n",
       " '[Sn+2]': 183,\n",
       " '[P@@+1]': 94,\n",
       " '[/S+1]': 47,\n",
       " '[-/Ring1]': 129,\n",
       " '[NH0]': 148,\n",
       " '[O]': 20,\n",
       " '[\\\\B-1]': 64,\n",
       " '[O-1]': 58,\n",
       " '[17F]': 143,\n",
       " '[OH0]': 71,\n",
       " '[=N-1]': 161,\n",
       " '[\\\\P@@]': 113}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_molgen.get_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7906f6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "185"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer_molgen.get_vocab())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2af1cb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./tokenizers/tokenizer_selfies/tokenizer_config.json',\n",
       " './tokenizers/tokenizer_selfies/special_tokens_map.json',\n",
       " './tokenizers/tokenizer_selfies/vocab.json',\n",
       " './tokenizers/tokenizer_selfies/merges.txt',\n",
       " './tokenizers/tokenizer_selfies/added_tokens.json',\n",
       " './tokenizers/tokenizer_selfies/tokenizer.json')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_molgen.save_pretrained(\"./tokenizers/tokenizer_selfies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fa8c1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
